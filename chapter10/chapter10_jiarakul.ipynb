{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "colab": {
      "name": "chapter10_jiarakul.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UWxN_ohUn-N"
      },
      "source": [
        "# 第10章: 機械翻訳"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izBkt0YTUn-O"
      },
      "source": [
        "## 90. データの準備"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fA10zLqCUn-O",
        "outputId": "f2aa0978-6be6-45f5-d572-25597aba8c01"
      },
      "source": [
        "!pip install -U ginza"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ginza\n",
            "  Downloading ginza-4.0.6.tar.gz (20 kB)\n",
            "Collecting spacy<3.0.0,>=2.3.2\n",
            "  Downloading spacy-2.3.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4 MB 9.8 MB/s \n",
            "\u001b[?25hCollecting ja_ginza<4.1.0,>=4.0.0\n",
            "  Downloading ja_ginza-4.0.0.tar.gz (51.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 51.5 MB 15 kB/s \n",
            "\u001b[?25hCollecting SudachiPy>=0.4.9\n",
            "  Downloading SudachiPy-0.5.2.tar.gz (70 kB)\n",
            "\u001b[K     |████████████████████████████████| 70 kB 10.5 MB/s \n",
            "\u001b[?25hCollecting SudachiDict-core>=20200330\n",
            "  Downloading SudachiDict-core-20210608.tar.gz (9.1 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->ginza) (57.2.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->ginza) (1.19.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->ginza) (1.0.5)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->ginza) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->ginza) (3.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->ginza) (2.0.5)\n",
            "Collecting thinc<7.5.0,>=7.4.1\n",
            "  Downloading thinc-7.4.5-cp37-cp37m-manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 64.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->ginza) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->ginza) (0.8.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->ginza) (1.1.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->ginza) (2.23.0)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->ginza) (1.0.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.0.0,>=2.3.2->ginza) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.3.2->ginza) (4.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.3.2->ginza) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.3.2->ginza) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.3.2->ginza) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.3.2->ginza) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.3.2->ginza) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.3.2->ginza) (2021.5.30)\n",
            "Collecting sortedcontainers~=2.1.0\n",
            "  Downloading sortedcontainers-2.1.0-py2.py3-none-any.whl (28 kB)\n",
            "Collecting dartsclone~=0.9.0\n",
            "  Downloading dartsclone-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (473 kB)\n",
            "\u001b[K     |████████████████████████████████| 473 kB 66.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from dartsclone~=0.9.0->SudachiPy>=0.4.9->ginza) (0.29.23)\n",
            "Building wheels for collected packages: ginza, ja-ginza, SudachiDict-core, SudachiPy\n",
            "  Building wheel for ginza (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ginza: filename=ginza-4.0.6-py3-none-any.whl size=15793 sha256=d8752665920348c0dc18d89b1e64952d3705e6c95048dc085edc52598bfaab39\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/03/a1/4bd525bb359f897919e88c98c36e890ec27ce8da9c731a1206\n",
            "  Building wheel for ja-ginza (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ja-ginza: filename=ja_ginza-4.0.0-py3-none-any.whl size=51530814 sha256=fd77ad0ea6dbbea3e603ed3e8069fd4032d7cc5cd63214cd1420d2089dc068d5\n",
            "  Stored in directory: /root/.cache/pip/wheels/a8/f5/4a/5d4877342f912e0b7209d8a65e7ce39fe2c1a3c2511d59acfb\n",
            "  Building wheel for SudachiDict-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for SudachiDict-core: filename=SudachiDict_core-20210608-py3-none-any.whl size=71421461 sha256=9be56deee4831af62b7a25f95494960a387dddea070db6c25f37287520031103\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/3e/74/0beaa92bc46b8d5c14b53d2640f8c3d74cbb33b4ec1fc6c213\n",
            "  Building wheel for SudachiPy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for SudachiPy: filename=SudachiPy-0.5.2-cp37-cp37m-linux_x86_64.whl size=870281 sha256=cf71d123366d369a1e070a4ac8b159eafe1bdfb29051973b07097338af50e8c4\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/72/0f/1c62895bde30566c65602f15ddbfa0b2bbc273f8c43c190a45\n",
            "Successfully built ginza ja-ginza SudachiDict-core SudachiPy\n",
            "Installing collected packages: thinc, sortedcontainers, dartsclone, SudachiPy, spacy, SudachiDict-core, ja-ginza, ginza\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: sortedcontainers\n",
            "    Found existing installation: sortedcontainers 2.4.0\n",
            "    Uninstalling sortedcontainers-2.4.0:\n",
            "      Successfully uninstalled sortedcontainers-2.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "Successfully installed SudachiDict-core-20210608 SudachiPy-0.5.2 dartsclone-0.9.0 ginza-4.0.6 ja-ginza-4.0.0 sortedcontainers-2.1.0 spacy-2.3.7 thinc-7.4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5f9DpS5HCoE",
        "outputId": "65d8f609-a448-412d-8add-f61654f69b1e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMDkG8TkzXSC",
        "outputId": "52118280-bc1b-47ec-a2c9-6e3ecd55ba12"
      },
      "source": [
        "%cd /content/drive/MyDrive/ColabNotebooks/chapter10"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/ColabNotebooks/chapter10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNltdJXWUn-P"
      },
      "source": [
        "!cat /content/drive/MyDrive/ColabNotebooks/chapter10/kftt-data-1.0/data/orig/kyoto-train.ja | sed 's/\\s+/ /g' | ginzame > train.ginza.ja"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shOh1RD0Un-P"
      },
      "source": [
        "!cat /content/drive/MyDrive/ColabNotebooks/chapter10/kftt-data-1.0/data/orig/kyoto-dev.ja | sed 's/\\s+/ /g' | ginzame > dev.ginza.ja\n",
        "!cat /content/drive/MyDrive/ColabNotebooks/chapter10/kftt-data-1.0/data/orig/kyoto-test.ja | sed 's/\\s+/ /g' | ginzame > test.ginza.ja"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LK4gQmnUn-P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2b707ff-a937-4a3b-e298-06b068ee8dec"
      },
      "source": [
        "!head -60 dev.ginza.ja"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "臨済\t名詞,普通名詞,一般,*,*,*,臨済,リンザイ,*\n",
            "宗\t接尾辞,名詞的,一般,*,*,*,宗,シュウ,*\n",
            "（\t補助記号,括弧開,*,*,*,*,（,キゴウ,*\n",
            "臨濟\t名詞,普通名詞,一般,*,*,*,臨済,リンザイ,*\n",
            "宗\t接尾辞,名詞的,一般,*,*,*,宗,シュウ,*\n",
            "、\t補助記号,読点,*,*,*,*,、,、,*\n",
            "りん\t名詞,普通名詞,一般,*,*,*,燐,リン,*\n",
            "ざい\t接尾辞,名詞的,一般,*,*,*,ざい,ザイ,*\n",
            "しゅう\t名詞,普通名詞,助数詞可能,*,*,*,周,シュウ,*\n",
            "）\t補助記号,括弧閉,*,*,*,*,）,キゴウ,*\n",
            "は\t助詞,係助詞,*,*,*,*,は,ハ,*\n",
            "、\t補助記号,読点,*,*,*,*,、,、,*\n",
            "中国\t名詞,固有名詞,地名,国,*,*,中国,チュウゴク,*\n",
            "禅\t名詞,普通名詞,一般,*,*,*,禅,ゼン,*\n",
            "五家\t名詞,普通名詞,一般,*,*,*,五家,ゴカ,*\n",
            "七宗\t名詞,固有名詞,地名,一般,*,*,七宗,ヒチソウ,*\n",
            "（\t補助記号,括弧開,*,*,*,*,（,キゴウ,*\n",
            "ごけ\t名詞,普通名詞,一般,*,*,*,苔,ゴケ,*\n",
            "しち\t名詞,数詞,*,*,*,*,七,シチ,*\n",
            "しゅう\t名詞,普通名詞,助数詞可能,*,*,*,周,シュウ,*\n",
            "）\t補助記号,括弧閉,*,*,*,*,）,キゴウ,*\n",
            "（\t補助記号,括弧開,*,*,*,*,（,キゴウ,*\n",
            "臨済\t名詞,普通名詞,一般,*,*,*,臨済,リンザイ,*\n",
            "、\t補助記号,読点,*,*,*,*,、,、,*\n",
            "潙仰\t名詞,固有名詞,一般,*,*,*,潙仰,イギョウ,*\n",
            "宗\t接尾辞,名詞的,一般,*,*,*,宗,シュウ,*\n",
            "、\t補助記号,読点,*,*,*,*,、,、,*\n",
            "曹洞\t名詞,固有名詞,一般,*,*,*,曹洞,ソウトウ,*\n",
            "宗\t接尾辞,名詞的,一般,*,*,*,宗,シュウ,*\n",
            "、\t補助記号,読点,*,*,*,*,、,、,*\n",
            "雲門\t名詞,固有名詞,人名,一般,*,*,雲門,ウンモン,*\n",
            "宗\t接尾辞,名詞的,一般,*,*,*,宗,シュウ,*\n",
            "、\t補助記号,読点,*,*,*,*,、,、,*\n",
            "法眼\t名詞,固有名詞,人名,姓,*,*,法眼,ホウゲン,*\n",
            "宗\t名詞,固有名詞,人名,名,*,*,宗,タカシ,*\n",
            "）\t補助記号,括弧閉,*,*,*,*,）,キゴウ,*\n",
            "の\t助詞,格助詞,*,*,*,*,の,ノ,*\n",
            "ひと\t名詞,数詞,*,*,*,*,一,ヒト,*\n",
            "つ\t接尾辞,名詞的,助数詞,*,*,*,つ,ツ,*\n",
            "で\t助動詞,*,*,*,助動詞-ダ,連用形-一般,だ,デ,*\n",
            "、\t補助記号,読点,*,*,*,*,、,、,*\n",
            "唐\t名詞,固有名詞,地名,国,*,*,唐,トウ,*\n",
            "の\t助詞,格助詞,*,*,*,*,の,ノ,*\n",
            "臨済\t名詞,普通名詞,一般,*,*,*,臨済,リンザイ,*\n",
            "義玄\t名詞,固有名詞,人名,名,*,*,義玄,ギゲン,*\n",
            "（\t補助記号,括弧開,*,*,*,*,（,キゴウ,*\n",
            "？\t補助記号,句点,*,*,*,*,？,キゴウ,*\n",
            "-\t補助記号,一般,*,*,*,*,-,キゴウ,*\n",
            "867\t名詞,数詞,*,*,*,*,867,ハチロクナナ,*\n",
            "年\t名詞,普通名詞,助数詞可能,*,*,*,年,ネン,*\n",
            "）\t補助記号,括弧閉,*,*,*,*,）,キゴウ,*\n",
            "を\t助詞,格助詞,*,*,*,*,を,ヲ,*\n",
            "宗祖\t名詞,普通名詞,一般,*,*,*,宗祖,シュウソ,*\n",
            "と\t助詞,格助詞,*,*,*,*,と,ト,*\n",
            "する\t動詞,非自立可能,*,*,サ行変格,終止形-一般,為る,スル,*\n",
            "。\t補助記号,句点,*,*,*,*,。,。,*\n",
            "EOS\n",
            "\n",
            "彼\t代名詞,*,*,*,*,*,彼,カレ,*\n",
            "は\t助詞,係助詞,*,*,*,*,は,ハ,*\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "4FkBOEruUn-P"
      },
      "source": [
        "source_target = [\n",
        "  ('train.ginza.ja', 'train.tokenized.ja'),\n",
        "  ('dev.ginza.ja', 'dev.tokenized.ja'),\n",
        "  ('test.ginza.ja', 'test.tokenized.ja')\n",
        "]\n",
        "\n",
        "for pair in source_target:\n",
        "  with open(pair[0]) as file:\n",
        "    list_sentence = []\n",
        "    list_word = []\n",
        "    for line in file:\n",
        "      line = line.split(sep='\\t')[0]\n",
        "      if line == 'EOS\\n':\n",
        "        list_sentence.append(' '.join(list_word))\n",
        "        list_word = []\n",
        "      elif line != '\\n':\n",
        "        list_word.append(line)\n",
        "  with open(pair[1], 'w') as writefile:\n",
        "    for line in list_sentence:\n",
        "      print(line, file=writefile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ylsEnD2Un-Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a187f14-f1a0-48bf-b7dd-3ede8f3e5976"
      },
      "source": [
        "!head -10 train.tokenized.ja"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "雪舟 （ せっ しゅう 、 1420 年 （ 応永 27 年 ） - 1506 年 （ 永正 3 年 ） ） は 号 で 、 15 世紀 後半 室町 時代 に 活躍 し た 水墨 画家 ・ 禅僧 で 、 画聖 と も 称え られる 。\n",
            "日本 の 水墨 画 を 一変 さ せ た 。\n",
            "諱 は 「 等楊 （ とう よう ） 」 、 もしくは 「 拙 宗 （ せっ しゅう ） 」 と 号し た 。\n",
            "備中 国 に 生まれ 、 京都 ・ 相国 寺 に 入っ て から 周防 国 に 移る 。\n",
            "その 後 遣明 使 に 随行 し て 中国 （ 明 ） に 渡っ て 中国 の 水墨 画 を 学ん だ 。\n",
            "作品 は 数多く 、 中国 風 の 山水 画 だけ で なく 人物 画 や 花鳥 画 も よく し た 。\n",
            "大胆 な 構図 と 力強い 筆線 は 非常 に 個性 的 な 画風 を 作り 出し て いる 。\n",
            "現存 する 作品 の うち 6 点 が 国宝 に 指定 さ れ て おり 、 日本 の 画家 の なか で も 別格 の 評価 を 受け て いる と いえる 。\n",
            "この ため 、 花鳥 図 屏風 など に 「 伝 雪舟 筆 」 さ れる 作品 は 大変 多い 。\n",
            "真筆 で ある か 専門 家 の 間 で も 意見 の 分かれる もの も 多々 ある 。\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrIa7KFmUn-Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3f33358-988d-4efb-c0ed-9a3b92ac148e"
      },
      "source": [
        "!pip install -U spacy==2.3.7"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy==2.3.7 in /usr/local/lib/python3.7/dist-packages (2.3.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.7) (2.23.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.7) (0.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.7) (1.19.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.7) (1.1.3)\n",
            "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.7) (7.4.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.7) (3.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.7) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.7) (1.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.7) (57.2.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.7) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.7) (2.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.7) (4.41.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.3.7) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy==2.3.7) (4.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.3.7) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy==2.3.7) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.7) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.7) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.7) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.3.7) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZxVzHEFUn-R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c6b9fc8-6075-4ce2-ae4e-9dcafb8a9a9c"
      },
      "source": [
        "!python3 -m spacy download en"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_sm==2.3.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 32 kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<2.4.0,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.3.1) (2.3.7)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (57.2.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.19.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\n",
            "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.23.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.1.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.41.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.4.1)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.7.4.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.10)\n",
            "Building wheels for collected packages: en-core-web-sm\n",
            "  Building wheel for en-core-web-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.3.1-py3-none-any.whl size=12047105 sha256=29e7f5521af1826f220feee728d7275c0cfd3a5e95f3d6d25a0cb6351c432c19\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/0d/f0/7ecae8427c515065d75410989e15e5785dd3975fe06e795cd9\n",
            "Successfully built en-core-web-sm\n",
            "Installing collected packages: en-core-web-sm\n",
            "  Attempting uninstall: en-core-web-sm\n",
            "    Found existing installation: en-core-web-sm 2.2.5\n",
            "    Uninstalling en-core-web-sm-2.2.5:\n",
            "      Successfully uninstalled en-core-web-sm-2.2.5\n",
            "Successfully installed en-core-web-sm-2.3.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vL2U55vkUn-R"
      },
      "source": [
        "import re\n",
        "import spacy\n",
        "\n",
        "en_source_target = [\n",
        "  ('/content/drive/MyDrive/ColabNotebooks/chapter10/kftt-data-1.0/data/orig/kyoto-train.en', 'train.tokenized.en'),\n",
        "  ('/content/drive/MyDrive/ColabNotebooks/chapter10/kftt-data-1.0/data/orig/kyoto-dev.en', 'dev.tokenized.en'),\n",
        "  ('/content/drive/MyDrive/ColabNotebooks/chapter10/kftt-data-1.0/data/orig/kyoto-test.en', 'test.tokenized.en')\n",
        "]\n",
        "\n",
        "nlp = spacy.load('en')\n",
        "for pair in en_source_target:\n",
        "  with open(pair[0]) as file, open(pair[1],'w') as writefile:\n",
        "    for line in file:\n",
        "      line = line.strip()\n",
        "      line = re.sub(r'\\s+',' ', line)\n",
        "      line = nlp.make_doc(line)\n",
        "      line = ' '.join([x.text for x in line])\n",
        "      print(line, file=writefile)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdHyMwmSUn-R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5d8f96f-daa6-4069-f2e6-0df07d808927"
      },
      "source": [
        "!head -10 train.tokenized.en"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Known as Sesshu ( 1420 - 1506 ) , he was an ink painter and Zen monk active in the Muromachi period in the latter half of the 15th century , and was called a master painter .\n",
            "He revolutionized the Japanese ink painting .\n",
            "He was given the posthumous name \" Toyo \" or \" Sesshu ( 拙宗 ) . \"\n",
            "Born in Bicchu Province , he moved to Suo Province after entering SShokoku - ji Temple in Kyoto .\n",
            "Later he accompanied a mission to Ming Dynasty China and learned Chinese ink painting .\n",
            "His works were many , including not only Chinese - style landscape paintings , but also portraits and pictures of flowers and birds .\n",
            "His bold compositions and strong brush strokes constituted an extremely distinctive style .\n",
            "6 of his extant works are designated national treasures . Indeed , he is considered to be extraordinary among Japanese painters .\n",
            "For this reason , there are a great many artworks that are attributed to him , such as folding screens with pictures of flowers and that birds are painted on them .\n",
            "There are many works that even experts can not agree if they are really his work or not .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGcuguaEUn-R"
      },
      "source": [
        "## 91. 機械翻訳モデルの訓練"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 813
        },
        "id": "XmOmNNkxUn-S",
        "outputId": "6632e601-c896-486c-d61d-22660bb2cc43"
      },
      "source": [
        "!pip install fairseq==0.10.2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fairseq==0.10.2\n",
            "  Downloading fairseq-0.10.2-cp37-cp37m-manylinux1_x86_64.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 6.8 MB/s \n",
            "\u001b[?25hCollecting hydra-core\n",
            "  Downloading hydra_core-1.1.0-py3-none-any.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 10.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.7/dist-packages (from fairseq==0.10.2) (1.14.6)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from fairseq==0.10.2) (1.9.0+cu102)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fairseq==0.10.2) (1.19.5)\n",
            "Collecting sacrebleu>=1.4.12\n",
            "  Downloading sacrebleu-1.5.1-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from fairseq==0.10.2) (2019.12.20)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from fairseq==0.10.2) (0.29.23)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fairseq==0.10.2) (4.41.1)\n",
            "Collecting dataclasses\n",
            "  Downloading dataclasses-0.6-py3-none-any.whl (14 kB)\n",
            "Collecting portalocker==2.0.0\n",
            "  Downloading portalocker-2.0.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi->fairseq==0.10.2) (2.20)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core->fairseq==0.10.2) (5.2.0)\n",
            "Collecting omegaconf==2.1.*\n",
            "  Downloading omegaconf-2.1.0-py3-none-any.whl (74 kB)\n",
            "\u001b[K     |████████████████████████████████| 74 kB 2.8 MB/s \n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 11.1 MB/s \n",
            "\u001b[?25hCollecting PyYAML>=5.1.*\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 9.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core->fairseq==0.10.2) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->fairseq==0.10.2) (3.7.4.3)\n",
            "Building wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141229 sha256=216442b697bbf7c9f9f1b968680d87442310622fd8f754461d6c792c92a1ffb1\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: PyYAML, antlr4-python3-runtime, portalocker, omegaconf, sacrebleu, hydra-core, dataclasses, fairseq\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-5.4.1 antlr4-python3-runtime-4.8 dataclasses-0.6 fairseq-0.10.2 hydra-core-1.1.0 omegaconf-2.1.0 portalocker-2.0.0 sacrebleu-1.5.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z3if5eFUn-S"
      },
      "source": [
        "fairseq-preprocess arguments: https://fairseq.readthedocs.io/en/latest/command_line_tools.html#fairseq-preprocess"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYl-a4uyUn-S",
        "outputId": "3d8e6cce-fd0f-4db0-c1cd-64b46758026c"
      },
      "source": [
        "!fairseq-preprocess --source-lang ja --target-lang en \\\n",
        "  --trainpref train.tokenized \\\n",
        "  --validpref dev.tokenized \\\n",
        "  --destdir for91 \\\n",
        "  --thresholdsrc 10 \\\n",
        "  --thresholdtgt 10 \\\n",
        "  --workers 20"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-20 06:28:53 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='for91', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=False, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='ja', srcdict=None, target_lang='en', task='translation', tensorboard_logdir=None, testpref=None, tgtdict=None, threshold_loss_scale=None, thresholdsrc=10, thresholdtgt=10, tokenizer=None, tpu=False, trainpref='train.tokenized', user_dir=None, validpref='dev.tokenized', workers=20)\n",
            "2021-07-20 06:30:04 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 37408 types\n",
            "2021-07-20 06:31:18 | INFO | fairseq_cli.preprocess | [ja] train.tokenized.ja: 440288 sents, 11571161 tokens, 2.12% replaced by <unk>\n",
            "2021-07-20 06:31:18 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 37408 types\n",
            "2021-07-20 06:31:20 | INFO | fairseq_cli.preprocess | [ja] dev.tokenized.ja: 1166 sents, 26509 tokens, 2.01% replaced by <unk>\n",
            "2021-07-20 06:31:20 | INFO | fairseq_cli.preprocess | [en] Dictionary: 37472 types\n",
            "2021-07-20 06:32:15 | INFO | fairseq_cli.preprocess | [en] train.tokenized.en: 440288 sents, 12320142 tokens, 2.54% replaced by <unk>\n",
            "2021-07-20 06:32:15 | INFO | fairseq_cli.preprocess | [en] Dictionary: 37472 types\n",
            "2021-07-20 06:32:16 | INFO | fairseq_cli.preprocess | [en] dev.tokenized.en: 1166 sents, 26093 tokens, 3.66% replaced by <unk>\n",
            "2021-07-20 06:32:16 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to for91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSVj4ACCUn-S"
      },
      "source": [
        "fairseq-train arguments: https://fairseq.readthedocs.io/en/latest/command_line_tools.html#fairseq-train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5A_ah9YBUn-T",
        "outputId": "ef8dd78c-5e53-45e9-dc88-c89717aa771b"
      },
      "source": [
        "!fairseq-train for91 \\\n",
        "  --fp16 \\\n",
        "  --save-dir save91 \\\n",
        "  --max-epoch 10 \\\n",
        "  --arch transformer \\\n",
        "  --encoder-normalize-before --decoder-normalize-before \\\n",
        "  --share-decoder-input-output-embed \\\n",
        "  --lr 0.001 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 \\\n",
        "  --update-freq 2 \\\n",
        "  --weight-decay 0.0001 \\\n",
        "  --dropout 0.2 --attention-dropout 0.1 --activation-dropout 0.1 \\\n",
        "  --optimizer adam --adam-betas '(0.9, 0.999)' \\\n",
        "  --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
        "  --max-tokens 4000 > log91.log"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 001: 100% 1810/1811 [10:00<00:00,  3.12it/s, loss=7.203, nll_loss=5.947, ppl=61.69, wps=19949.3, ups=3, wpb=6651.8, bsz=239.5, num_updates=1800, lr=0.000450055, gnorm=0.691, loss_scale=16, train_wall=33, wall=598]\n",
            "epoch 001 | valid on 'valid' subset:   0% 0/13 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:   8% 1/13 [00:00<00:01,  9.27it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  31% 4/13 [00:00<00:00, 11.09it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  46% 6/13 [00:00<00:00, 12.75it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  62% 8/13 [00:00<00:00, 14.22it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  77% 10/13 [00:00<00:00, 15.25it/s]\u001b[A\n",
            "epoch 001 | valid on 'valid' subset:  92% 12/13 [00:00<00:00, 15.72it/s]\u001b[A\n",
            "epoch 002: 100% 1810/1811 [10:05<00:00,  2.92it/s, loss=5.996, nll_loss=4.521, ppl=22.96, wps=20537.6, ups=3, wpb=6838.5, bsz=257.8, num_updates=3600, lr=0.00090001, gnorm=0.6, loss_scale=16, train_wall=33, wall=1251]\n",
            "epoch 002 | valid on 'valid' subset:   0% 0/13 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  15% 2/13 [00:00<00:00, 13.67it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  31% 4/13 [00:00<00:00, 15.09it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  46% 6/13 [00:00<00:00, 16.24it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  62% 8/13 [00:00<00:00, 17.11it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  77% 10/13 [00:00<00:00, 17.50it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  92% 12/13 [00:00<00:00, 17.35it/s]\u001b[A\n",
            "epoch 003: 100% 1810/1811 [10:04<00:00,  3.07it/s, loss=5.309, nll_loss=3.745, ppl=13.41, wps=20141, ups=3.01, wpb=6689.9, bsz=233.4, num_updates=5400, lr=0.000860663, gnorm=0.439, loss_scale=16, train_wall=33, wall=1911]\n",
            "epoch 003 | valid on 'valid' subset:   0% 0/13 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:   8% 1/13 [00:00<00:01,  8.73it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  23% 3/13 [00:00<00:00, 10.44it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  38% 5/13 [00:00<00:00, 12.15it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  54% 7/13 [00:00<00:00, 13.70it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  69% 9/13 [00:00<00:00, 15.03it/s]\u001b[A\n",
            "epoch 003 | valid on 'valid' subset:  85% 11/13 [00:00<00:00, 15.77it/s]\u001b[A\n",
            "epoch 004: 100% 1810/1811 [10:03<00:00,  3.21it/s, loss=4.914, nll_loss=3.302, ppl=9.86, wps=20288.8, ups=2.97, wpb=6835.4, bsz=257, num_updates=7200, lr=0.000745356, gnorm=0.372, loss_scale=16, train_wall=33, wall=2570]\n",
            "epoch 004 | valid on 'valid' subset:   0% 0/13 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 004 | valid on 'valid' subset:   8% 1/13 [00:00<00:01,  8.79it/s]\u001b[A\n",
            "epoch 004 | valid on 'valid' subset:  23% 3/13 [00:00<00:00, 10.49it/s]\u001b[A\n",
            "epoch 004 | valid on 'valid' subset:  46% 6/13 [00:00<00:00, 12.24it/s]\u001b[A\n",
            "epoch 004 | valid on 'valid' subset:  62% 8/13 [00:00<00:00, 13.77it/s]\u001b[A\n",
            "epoch 004 | valid on 'valid' subset:  77% 10/13 [00:00<00:00, 14.88it/s]\u001b[A\n",
            "epoch 004 | valid on 'valid' subset:  92% 12/13 [00:00<00:00, 15.49it/s]\u001b[A\n",
            "epoch 005: 100% 1810/1811 [10:03<00:00,  3.06it/s, loss=4.719, nll_loss=3.083, ppl=8.47, wps=20507.5, ups=2.97, wpb=6907.1, bsz=246.1, num_updates=9000, lr=0.000666667, gnorm=0.338, loss_scale=32, train_wall=33, wall=3229]\n",
            "epoch 005 | valid on 'valid' subset:   0% 0/13 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 005 | valid on 'valid' subset:   8% 1/13 [00:00<00:01,  8.85it/s]\u001b[A\n",
            "epoch 005 | valid on 'valid' subset:  23% 3/13 [00:00<00:00, 10.51it/s]\u001b[A\n",
            "epoch 005 | valid on 'valid' subset:  46% 6/13 [00:00<00:00, 12.27it/s]\u001b[A\n",
            "epoch 005 | valid on 'valid' subset:  62% 8/13 [00:00<00:00, 13.83it/s]\u001b[A\n",
            "epoch 005 | valid on 'valid' subset:  77% 10/13 [00:00<00:00, 14.95it/s]\u001b[A\n",
            "epoch 005 | valid on 'valid' subset:  92% 12/13 [00:00<00:00, 15.54it/s]\u001b[A\n",
            "epoch 006: 100% 1810/1811 [10:06<00:00,  2.99it/s, loss=4.59, nll_loss=2.936, ppl=7.65, wps=20413.1, ups=3.01, wpb=6789.9, bsz=251, num_updates=10800, lr=0.000608581, gnorm=0.337, loss_scale=32, train_wall=33, wall=3889]\n",
            "epoch 006 | valid on 'valid' subset:   0% 0/13 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 006 | valid on 'valid' subset:   8% 1/13 [00:00<00:01,  8.42it/s]\u001b[A\n",
            "epoch 006 | valid on 'valid' subset:  23% 3/13 [00:00<00:00, 10.16it/s]\u001b[A\n",
            "epoch 006 | valid on 'valid' subset:  38% 5/13 [00:00<00:00, 11.89it/s]\u001b[A\n",
            "epoch 006 | valid on 'valid' subset:  54% 7/13 [00:00<00:00, 13.44it/s]\u001b[A\n",
            "epoch 006 | valid on 'valid' subset:  69% 9/13 [00:00<00:00, 14.79it/s]\u001b[A\n",
            "epoch 006 | valid on 'valid' subset:  85% 11/13 [00:00<00:00, 15.55it/s]\u001b[A\n",
            "epoch 007: 100% 1810/1811 [10:04<00:00,  2.96it/s, loss=4.468, nll_loss=2.799, ppl=6.96, wps=20406.9, ups=3, wpb=6800.6, bsz=226.2, num_updates=12600, lr=0.000563436, gnorm=0.317, loss_scale=32, train_wall=33, wall=4576]\n",
            "epoch 007 | valid on 'valid' subset:   0% 0/13 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 007 | valid on 'valid' subset:   8% 1/13 [00:00<00:01,  8.20it/s]\u001b[A\n",
            "epoch 007 | valid on 'valid' subset:  23% 3/13 [00:00<00:01,  9.94it/s]\u001b[A\n",
            "epoch 007 | valid on 'valid' subset:  38% 5/13 [00:00<00:00, 11.65it/s]\u001b[A\n",
            "epoch 007 | valid on 'valid' subset:  54% 7/13 [00:00<00:00, 13.24it/s]\u001b[A\n",
            "epoch 007 | valid on 'valid' subset:  69% 9/13 [00:00<00:00, 14.61it/s]\u001b[A\n",
            "epoch 007 | valid on 'valid' subset:  85% 11/13 [00:00<00:00, 15.28it/s]\u001b[A\n",
            "epoch 008: 100% 1810/1811 [10:04<00:00,  2.93it/s, loss=4.367, nll_loss=2.684, ppl=6.43, wps=20456.2, ups=3.01, wpb=6798.6, bsz=239, num_updates=14400, lr=0.000527046, gnorm=0.309, loss_scale=32, train_wall=33, wall=5234]\n",
            "epoch 008 | valid on 'valid' subset:   0% 0/13 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 008 | valid on 'valid' subset:   8% 1/13 [00:00<00:01,  8.16it/s]\u001b[A\n",
            "epoch 008 | valid on 'valid' subset:  31% 4/13 [00:00<00:00,  9.96it/s]\u001b[A\n",
            "epoch 008 | valid on 'valid' subset:  46% 6/13 [00:00<00:00, 11.70it/s]\u001b[A\n",
            "epoch 008 | valid on 'valid' subset:  62% 8/13 [00:00<00:00, 13.29it/s]\u001b[A\n",
            "epoch 008 | valid on 'valid' subset:  77% 10/13 [00:00<00:00, 14.48it/s]\u001b[A\n",
            "epoch 008 | valid on 'valid' subset:  92% 12/13 [00:00<00:00, 15.18it/s]\u001b[A\n",
            "epoch 009: 100% 1810/1811 [10:03<00:00,  3.14it/s, loss=4.26, nll_loss=2.562, ppl=5.91, wps=20207.2, ups=2.99, wpb=6767.5, bsz=256.8, num_updates=16200, lr=0.000496904, gnorm=0.307, loss_scale=32, train_wall=33, wall=5892]\n",
            "epoch 009 | valid on 'valid' subset:   0% 0/13 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 009 | valid on 'valid' subset:   8% 1/13 [00:00<00:01,  8.68it/s]\u001b[A\n",
            "epoch 009 | valid on 'valid' subset:  23% 3/13 [00:00<00:00, 10.41it/s]\u001b[A\n",
            "epoch 009 | valid on 'valid' subset:  38% 5/13 [00:00<00:00, 12.13it/s]\u001b[A\n",
            "epoch 009 | valid on 'valid' subset:  54% 7/13 [00:00<00:00, 13.68it/s]\u001b[A\n",
            "epoch 009 | valid on 'valid' subset:  69% 9/13 [00:00<00:00, 15.01it/s]\u001b[A\n",
            "epoch 009 | valid on 'valid' subset:  85% 11/13 [00:00<00:00, 15.71it/s]\u001b[A\n",
            "epoch 010: 100% 1810/1811 [10:03<00:00,  2.97it/s, loss=4.205, nll_loss=2.499, ppl=5.65, wps=20420.9, ups=3, wpb=6797.5, bsz=260.4, num_updates=18100, lr=0.0004701, gnorm=0.305, loss_scale=64, train_wall=33, wall=6582]\n",
            "epoch 010 | valid on 'valid' subset:   0% 0/13 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 010 | valid on 'valid' subset:   8% 1/13 [00:00<00:01,  8.34it/s]\u001b[A\n",
            "epoch 010 | valid on 'valid' subset:  23% 3/13 [00:00<00:01,  9.95it/s]\u001b[A\n",
            "epoch 010 | valid on 'valid' subset:  46% 6/13 [00:00<00:00, 11.73it/s]\u001b[A\n",
            "epoch 010 | valid on 'valid' subset:  62% 8/13 [00:00<00:00, 13.35it/s]\u001b[A\n",
            "epoch 010 | valid on 'valid' subset:  77% 10/13 [00:00<00:00, 14.52it/s]\u001b[A\n",
            "epoch 010 | valid on 'valid' subset:  92% 12/13 [00:00<00:00, 15.19it/s]\u001b[A\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqRKWrBYgwMX"
      },
      "source": [
        "## 92. 機械翻訳モデルの適用"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBsjYoFHgzhv",
        "outputId": "a62a99af-b56d-4d6c-d768-d63ebdd5dfcf"
      },
      "source": [
        "!fairseq-interactive --path save91/checkpoint_best.pt for91 < test.tokenized.ja | grep '^H' | cut -f3 > 92.out"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
            "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
            "  return torch.floor_divide(self, other)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_pzoFA4SvA6"
      },
      "source": [
        "## 93. BLEUスコアの計測"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eR4Emji4h01H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e7d7f3e-ce4b-46c9-ac6a-bad33e2cdcb1"
      },
      "source": [
        "!fairseq-score --sys 92.out --ref test.tokenized.en"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(ignore_case=False, order=4, ref='test.tokenized.en', sacrebleu=False, sentence_bleu=False, sys='92.out')\n",
            "BLEU4 = 6.96, 30.1/9.9/4.2/1.9 (BP=1.000, ratio=1.076, syslen=29721, reflen=27628)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pO-73WCS6t3"
      },
      "source": [
        "## 94. ビーム探索"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkLpzakrTBO1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f54f0414-57ba-4276-9d41-e2b6054f1c6c"
      },
      "source": [
        "%%bash\n",
        "for N in {1..20}; do\n",
        "  fairseq-interactive for91\\\n",
        "    --path save91/checkpoint_last.pt \\\n",
        "    --buffer-size 128 \\\n",
        "    --batch-size 64 \\\n",
        "    --beam $N\\\n",
        "    --lenpen 0.6\\\n",
        "    < dev.tokenized.ja | grep '^H' | cut -f3 > 94.${N}.out\n",
        "done"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Process is terminated.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3dl3UeIURGD"
      },
      "source": [
        "%%bash\n",
        "for N in {1..20}; do\n",
        "  fairseq-score --sys 94.${N}.out --ref test.tokenized.en > 94.${N}.score\n",
        "done"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uaMc8d8vVJvC"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "\n",
        "def read_score(filename):\n",
        "  with open(filename) as f:\n",
        "    x = f.readlines()\n",
        "    x = re.search(r'(?<=BLEU4 = )\\d*\\.\\d*(?=,)', x)\n",
        "    return float(x.group())"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEoTavfHJ_nE"
      },
      "source": [
        "xs = range(1, 101)\n",
        "ys = [read_score(f'94.{x}.score') for x in xs]\n",
        "plt.plot(xs,ys)\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52Lf3DAC7KZh"
      },
      "source": [
        "## 95. サブワード化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNUeILaTJ_v4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30cb829d-6452-431b-f8f9-2d3c27fdd129"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 37.2 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 34.5 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 16.6 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81 kB 9.6 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 92 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 112 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████                            | 153 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 163 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 184 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 204 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████                          | 225 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 235 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 256 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████                         | 266 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 276 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 296 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████                        | 307 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 327 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 348 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 368 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 389 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 399 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 409 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 419 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 440 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 450 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 460 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 471 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 481 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 501 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 512 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 522 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 532 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 542 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 552 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 563 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 573 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 583 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 593 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 614 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 624 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 634 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 645 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 655 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 665 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 675 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 686 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 696 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 706 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 727 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 737 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 747 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 757 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 768 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 778 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 788 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 798 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 808 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 819 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 829 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 839 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 849 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 860 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 870 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 880 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 890 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 901 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 911 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 921 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 931 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 942 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 952 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 962 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 972 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 983 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 993 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.0 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.1 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.1 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2 MB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2 MB 9.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cfa50GsJ_5K"
      },
      "source": [
        "! cat train.tokenized.ja train.tokenized.en > train.tokenized.jaen"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWJpH9Rc7YMZ"
      },
      "source": [
        "import sentencepiece as spm"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdKeZJoI8-NY"
      },
      "source": [
        "spm.SentencePieceTrainer.Train(\n",
        "    input = 'train.tokenized.jaen',\n",
        "    model_prefix = 'kyoto',\n",
        "    model_type = 'bpe',\n",
        "    vocab_size = 16000,\n",
        "    character_coverage = 1.0,\n",
        "    num_threads = 16)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a45bMU6u-vfz",
        "outputId": "48f83273-e8e4-4b5e-f577-bfba7a9e49df"
      },
      "source": [
        "sp = spm.SentencePieceProcessor()\n",
        "sp.Load('kyoto.model')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7H97keH_B6j"
      },
      "source": [
        "def sp_encode(src, dst, alpha=None):\n",
        "  with open(src) as s, open(dst, 'w') as d:\n",
        "    for x in s:\n",
        "      x = x.strip()\n",
        "      x = re.sub(r'\\s+', ' ', x)\n",
        "      if alpha is None:\n",
        "        x = sp.encode(x, out_type=str)\n",
        "      else:\n",
        "        x = sp.encode(x, out_type=str, enable_sampling=True, alpha=alpha)\n",
        "      # x = sp.encode_as_pieces(x)\n",
        "      x = ' '.join(x)\n",
        "      print(x, file=d)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfmcEBcN_pVQ"
      },
      "source": [
        "dev_ja_src = 'dev.tokenized.ja'\n",
        "dev_en_src = 'dev.tokenized.en'\n",
        "test_ja_src = 'test.tokenized.ja'\n",
        "test_en_src = 'test.tokenized.en'\n",
        "dev_ja_dst = 'dev.sub.ja'\n",
        "dev_en_dst = 'dev.sub.en'\n",
        "test_ja_dst = 'test.sub.ja'\n",
        "test_en_dst = 'test.sub.en'\n",
        "\n",
        "sp_encode(dev_ja_src, dev_ja_dst)\n",
        "sp_encode(dev_en_src, dev_en_dst)\n",
        "sp_encode(test_ja_src, test_ja_dst)\n",
        "sp_encode(test_en_src,test_en_dst)\n",
        "\n",
        "#  Train Japanese\n",
        "for epoch in range(1, 11):\n",
        "  src = 'train.tokenized.ja'\n",
        "  dst = 'train.sub.{}.ja'.format(epoch)\n",
        "  sp_encode(src, dst, alpha=0.1)\n",
        "\n",
        "#  Train English\n",
        "for epoch in range(1, 11):\n",
        "  src = 'train.tokenized.en'\n",
        "  dst = 'train.sub.{}.en'.format(epoch)\n",
        "  sp_encode(src, dst, alpha=0.1)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fG6abeY0G6NM",
        "outputId": "1f603cab-b1d0-4a13-cacb-610db08fec8b"
      },
      "source": [
        "!head train.sub.1.ja"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "▁雪 舟 ▁( ▁せ っ ▁しゅ う ▁、 ▁14 20 ▁年 ▁( ▁応永 ▁27 ▁年 ▁) ▁- ▁150 6 ▁年 ▁( ▁永正 ▁3 ▁年 ▁) ▁) ▁は ▁号 ▁で ▁、 ▁15 ▁世紀 ▁後半 ▁室町 ▁時代 ▁に ▁活躍 ▁し ▁た ▁水 墨 ▁画 家 ▁・ ▁禅 僧 ▁で ▁ 、 ▁画 聖 ▁と ▁も ▁称 え ▁ ら れる ▁。\n",
            "▁日 本 ▁の ▁ 水 墨 ▁画 ▁を ▁一 変 ▁さ ▁せ ▁た ▁。\n",
            "▁諱 ▁ は ▁「 ▁等 楊 ▁( ▁とう ▁ よ う ▁) ▁」 ▁ 、 ▁もしくは ▁「 ▁ 拙 ▁宗 ▁( ▁せ っ ▁しゅ う ▁) ▁」 ▁と ▁号 し ▁た ▁。\n",
            "▁備 中 ▁国 ▁に ▁生まれ ▁、 ▁京都 ▁・ ▁相 国 ▁寺 ▁に ▁入っ ▁て ▁から ▁周 防 ▁ 国 ▁に ▁ 移 る ▁。\n",
            "▁その ▁後 ▁遣 明 ▁使 ▁に ▁随 行 ▁し ▁て ▁中国 ▁( ▁明 ▁) ▁ に ▁渡っ ▁て ▁中国 ▁の ▁水 墨 ▁画 ▁を ▁学ん ▁だ ▁。\n",
            "▁作品 ▁は ▁数多く ▁、 ▁中国 ▁風 ▁ の ▁山 水 ▁画 ▁だけ ▁で ▁なく ▁人物 ▁ 画 ▁や ▁花 鳥 ▁画 ▁も ▁よく ▁し ▁た ▁ 。\n",
            "▁大 胆 ▁な ▁構 図 ▁と ▁力 強 い ▁筆 線 ▁は ▁非 常 ▁に ▁個 性 ▁的 ▁な ▁画 風 ▁を ▁作り ▁出し ▁て ▁いる ▁ 。\n",
            "▁現 存 ▁する ▁作 品 ▁の ▁うち ▁6 ▁点 ▁が ▁国宝 ▁に ▁指定 ▁さ ▁れ ▁て ▁おり ▁、 ▁日本 ▁の ▁画 家 ▁の ▁なか ▁で ▁も ▁別 格 ▁の ▁評価 ▁を ▁受け ▁て ▁い る ▁と ▁いえる ▁。\n",
            "▁この ▁ため ▁ 、 ▁花 鳥 ▁図 ▁屏 風 ▁など ▁に ▁「 ▁伝 ▁ 雪 舟 ▁筆 ▁」 ▁さ ▁れる ▁作品 ▁は ▁大 変 ▁多い ▁。\n",
            "▁真 筆 ▁ で ▁ある ▁か ▁専門 ▁家 ▁ の ▁間 ▁で ▁も ▁意見 ▁の ▁分か れる ▁もの ▁も ▁多 々 ▁ある ▁。\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVtvQa0YG9kL",
        "outputId": "74b295c1-dab6-4c12-c8c1-255adc63727c"
      },
      "source": [
        "!head train.sub.1.en"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "▁K nown ▁as ▁S es shu ▁( ▁14 20 ▁- ▁150 6 ▁ ) ▁, ▁he ▁w as ▁an ▁ink ▁p a in ter ▁and ▁Zen ▁monk ▁active ▁in ▁t he ▁M ur om achi ▁per i od ▁in ▁the ▁latter ▁half ▁of ▁th e ▁15 th ▁century ▁, ▁and ▁was ▁called ▁a ▁m a s ter ▁painter ▁.\n",
            "▁He ▁revol ution ized ▁the ▁J a p an ese ▁ink ▁pain ting ▁ .\n",
            "▁He ▁was ▁g iv en ▁the ▁posthumous ▁name ▁\" ▁Toyo ▁\" ▁or ▁\" ▁Sess hu ▁( ▁ 拙 宗 ▁) ▁. ▁\"\n",
            "▁B orn ▁in ▁ B ic chu ▁Province ▁ , ▁he ▁moved ▁to ▁Su o ▁P ro v in ce ▁after ▁enter in g ▁ S S ho k ok u ▁- ▁ji ▁Temple ▁in ▁Kyoto ▁ .\n",
            "▁Later ▁ h e ▁accompanied ▁ a ▁mission ▁to ▁Ming ▁ D ynasty ▁C h ina ▁and ▁learned ▁Chinese ▁ink ▁painting ▁.\n",
            "▁His ▁work s ▁ w ere ▁many ▁ , ▁in c lud ing ▁not ▁o n ly ▁Chin es e ▁ - ▁sty le ▁l and s cape ▁paintings ▁, ▁but ▁also ▁port r ai ts ▁and ▁ p ict ures ▁of ▁flowers ▁and ▁b ir ds ▁.\n",
            "▁H is ▁b old ▁comp os i t ions ▁and ▁str on g ▁br ush ▁st ro k es ▁con stit uted ▁an ▁extremely ▁distinct ive ▁style ▁.\n",
            "▁6 ▁of ▁his ▁ext ant ▁works ▁are ▁designated ▁national ▁t r e asures ▁. ▁In de ed ▁, ▁he ▁is ▁con s id ered ▁to ▁be ▁extra ord in ar y ▁among ▁Japanese ▁pain ters ▁.\n",
            "▁For ▁this ▁re ason ▁, ▁there ▁are ▁a ▁ g reat ▁many ▁art wor ks ▁that ▁are ▁att ributed ▁to ▁him ▁, ▁such ▁as ▁ f old i n g ▁s c re ens ▁with ▁pictures ▁of ▁flowers ▁and ▁that ▁ b ir d s ▁a r e ▁painted ▁on ▁the m ▁.\n",
            "▁T he re ▁are ▁man y ▁works ▁that ▁even ▁ex per ts ▁can ▁not ▁agre e ▁if ▁they ▁are ▁real ly ▁his ▁wor k ▁or ▁not ▁.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMIgxkZVMbKZ",
        "outputId": "983b7f4a-6901-4517-b8b2-0062e4639d21"
      },
      "source": [
        "%%bash\n",
        "fairseq-preprocess -s ja -t en \\\n",
        "    --trainpref train.sub.1 \\\n",
        "    --validpref dev.sub \\\n",
        "    --destdir ch10/data95.1 \\\n",
        "    --joined-dictionary \\\n",
        "    --workers 16"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-27 04:21:20 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='ch10/data95.1', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='ja', srcdict=None, target_lang='en', task='translation', tensorboard_logdir=None, testpref=None, tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='train.sub.1', user_dir=None, validpref='dev.sub', workers=16)\n",
            "2021-07-27 04:22:56 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 16008 types\n",
            "2021-07-27 04:24:31 | INFO | fairseq_cli.preprocess | [ja] train.sub.1.ja: 440288 sents, 15795839 tokens, 0.0% replaced by <unk>\n",
            "2021-07-27 04:24:31 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 16008 types\n",
            "2021-07-27 04:24:32 | INFO | fairseq_cli.preprocess | [ja] dev.sub.ja: 1166 sents, 32484 tokens, 0.00924% replaced by <unk>\n",
            "2021-07-27 04:24:32 | INFO | fairseq_cli.preprocess | [en] Dictionary: 16008 types\n",
            "2021-07-27 04:26:10 | INFO | fairseq_cli.preprocess | [en] train.sub.1.en: 440288 sents, 20863656 tokens, 0.0% replaced by <unk>\n",
            "2021-07-27 04:26:10 | INFO | fairseq_cli.preprocess | [en] Dictionary: 16008 types\n",
            "2021-07-27 04:26:11 | INFO | fairseq_cli.preprocess | [en] dev.sub.en: 1166 sents, 34466 tokens, 0.0% replaced by <unk>\n",
            "2021-07-27 04:26:11 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to ch10/data95.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfdjG_hnByne",
        "outputId": "a0d0436f-5d90-4dbd-c9d5-b1a9f3fcb170"
      },
      "source": [
        "%%bash\n",
        "for N in {2..10}; do\n",
        "  fairseq-preprocess -s ja -t en \\\n",
        "    --trainpref train.sub.$N\\\n",
        "    --validpref dev.sub \\\n",
        "    --destdir data95.$N \\\n",
        "    --srcdict ch10/data95.1/dict.ja.txt \\\n",
        "    --joined-dictionary \\\n",
        "    --workers 16\n",
        "done"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-27 04:26:12 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data95.2', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='ja', srcdict='ch10/data95.1/dict.ja.txt', target_lang='en', task='translation', tensorboard_logdir=None, testpref=None, tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='train.sub.2', user_dir=None, validpref='dev.sub', workers=16)\n",
            "2021-07-27 04:26:12 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 16008 types\n",
            "2021-07-27 04:27:38 | INFO | fairseq_cli.preprocess | [ja] train.sub.2.ja: 440288 sents, 15795435 tokens, 0.0% replaced by <unk>\n",
            "2021-07-27 04:27:38 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 16008 types\n",
            "2021-07-27 04:27:38 | INFO | fairseq_cli.preprocess | [ja] dev.sub.ja: 1166 sents, 32484 tokens, 0.00924% replaced by <unk>\n",
            "2021-07-27 04:27:38 | INFO | fairseq_cli.preprocess | [en] Dictionary: 16008 types\n",
            "2021-07-27 04:29:11 | INFO | fairseq_cli.preprocess | [en] train.sub.2.en: 440288 sents, 20859258 tokens, 0.0% replaced by <unk>\n",
            "2021-07-27 04:29:11 | INFO | fairseq_cli.preprocess | [en] Dictionary: 16008 types\n",
            "2021-07-27 04:29:12 | INFO | fairseq_cli.preprocess | [en] dev.sub.en: 1166 sents, 34466 tokens, 0.0% replaced by <unk>\n",
            "2021-07-27 04:29:12 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data95.2\n",
            "2021-07-27 04:29:14 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data95.3', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='ja', srcdict='ch10/data95.1/dict.ja.txt', target_lang='en', task='translation', tensorboard_logdir=None, testpref=None, tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='train.sub.3', user_dir=None, validpref='dev.sub', workers=16)\n",
            "2021-07-27 04:29:14 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 16008 types\n",
            "2021-07-27 04:30:39 | INFO | fairseq_cli.preprocess | [ja] train.sub.3.ja: 440288 sents, 15796967 tokens, 0.0% replaced by <unk>\n",
            "2021-07-27 04:30:39 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 16008 types\n",
            "2021-07-27 04:30:40 | INFO | fairseq_cli.preprocess | [ja] dev.sub.ja: 1166 sents, 32484 tokens, 0.00924% replaced by <unk>\n",
            "2021-07-27 04:30:40 | INFO | fairseq_cli.preprocess | [en] Dictionary: 16008 types\n",
            "2021-07-27 04:32:16 | INFO | fairseq_cli.preprocess | [en] train.sub.3.en: 440288 sents, 20861226 tokens, 0.0% replaced by <unk>\n",
            "2021-07-27 04:32:16 | INFO | fairseq_cli.preprocess | [en] Dictionary: 16008 types\n",
            "2021-07-27 04:32:17 | INFO | fairseq_cli.preprocess | [en] dev.sub.en: 1166 sents, 34466 tokens, 0.0% replaced by <unk>\n",
            "2021-07-27 04:32:17 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data95.3\n",
            "2021-07-27 04:32:18 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data95.4', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='ja', srcdict='ch10/data95.1/dict.ja.txt', target_lang='en', task='translation', tensorboard_logdir=None, testpref=None, tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='train.sub.4', user_dir=None, validpref='dev.sub', workers=16)\n",
            "2021-07-27 04:32:18 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 16008 types\n",
            "2021-07-27 04:33:45 | INFO | fairseq_cli.preprocess | [ja] train.sub.4.ja: 440288 sents, 15802155 tokens, 0.0% replaced by <unk>\n",
            "2021-07-27 04:33:45 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 16008 types\n",
            "2021-07-27 04:33:46 | INFO | fairseq_cli.preprocess | [ja] dev.sub.ja: 1166 sents, 32484 tokens, 0.00924% replaced by <unk>\n",
            "2021-07-27 04:33:46 | INFO | fairseq_cli.preprocess | [en] Dictionary: 16008 types\n",
            "2021-07-27 04:35:20 | INFO | fairseq_cli.preprocess | [en] train.sub.4.en: 440288 sents, 20863301 tokens, 0.0% replaced by <unk>\n",
            "2021-07-27 04:35:20 | INFO | fairseq_cli.preprocess | [en] Dictionary: 16008 types\n",
            "2021-07-27 04:35:21 | INFO | fairseq_cli.preprocess | [en] dev.sub.en: 1166 sents, 34466 tokens, 0.0% replaced by <unk>\n",
            "2021-07-27 04:35:21 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data95.4\n",
            "2021-07-27 04:35:22 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data95.5', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='ja', srcdict='ch10/data95.1/dict.ja.txt', target_lang='en', task='translation', tensorboard_logdir=None, testpref=None, tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='train.sub.5', user_dir=None, validpref='dev.sub', workers=16)\n",
            "2021-07-27 04:35:22 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 16008 types\n",
            "2021-07-27 04:37:00 | INFO | fairseq_cli.preprocess | [ja] train.sub.5.ja: 440288 sents, 15799942 tokens, 0.0% replaced by <unk>\n",
            "2021-07-27 04:37:00 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 16008 types\n",
            "2021-07-27 04:37:01 | INFO | fairseq_cli.preprocess | [ja] dev.sub.ja: 1166 sents, 32484 tokens, 0.00924% replaced by <unk>\n",
            "2021-07-27 04:37:01 | INFO | fairseq_cli.preprocess | [en] Dictionary: 16008 types\n",
            "2021-07-27 04:38:37 | INFO | fairseq_cli.preprocess | [en] train.sub.5.en: 440288 sents, 20861654 tokens, 0.0% replaced by <unk>\n",
            "2021-07-27 04:38:37 | INFO | fairseq_cli.preprocess | [en] Dictionary: 16008 types\n",
            "2021-07-27 04:38:38 | INFO | fairseq_cli.preprocess | [en] dev.sub.en: 1166 sents, 34466 tokens, 0.0% replaced by <unk>\n",
            "2021-07-27 04:38:38 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data95.5\n",
            "2021-07-27 04:38:39 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data95.6', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='ja', srcdict='ch10/data95.1/dict.ja.txt', target_lang='en', task='translation', tensorboard_logdir=None, testpref=None, tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='train.sub.6', user_dir=None, validpref='dev.sub', workers=16)\n",
            "2021-07-27 04:38:39 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 16008 types\n",
            "2021-07-27 04:40:03 | INFO | fairseq_cli.preprocess | [ja] train.sub.6.ja: 440288 sents, 15800141 tokens, 0.0% replaced by <unk>\n",
            "2021-07-27 04:40:03 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 16008 types\n",
            "2021-07-27 04:40:04 | INFO | fairseq_cli.preprocess | [ja] dev.sub.ja: 1166 sents, 32484 tokens, 0.00924% replaced by <unk>\n",
            "2021-07-27 04:40:04 | INFO | fairseq_cli.preprocess | [en] Dictionary: 16008 types\n",
            "2021-07-27 04:41:38 | INFO | fairseq_cli.preprocess | [en] train.sub.6.en: 440288 sents, 20860819 tokens, 0.0% replaced by <unk>\n",
            "2021-07-27 04:41:38 | INFO | fairseq_cli.preprocess | [en] Dictionary: 16008 types\n",
            "2021-07-27 04:41:38 | INFO | fairseq_cli.preprocess | [en] dev.sub.en: 1166 sents, 34466 tokens, 0.0% replaced by <unk>\n",
            "2021-07-27 04:41:38 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data95.6\n",
            "2021-07-27 04:41:40 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data95.7', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='ja', srcdict='ch10/data95.1/dict.ja.txt', target_lang='en', task='translation', tensorboard_logdir=None, testpref=None, tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='train.sub.7', user_dir=None, validpref='dev.sub', workers=16)\n",
            "2021-07-27 04:41:40 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 16008 types\n",
            "2021-07-27 04:43:05 | INFO | fairseq_cli.preprocess | [ja] train.sub.7.ja: 440288 sents, 15797853 tokens, 0.0% replaced by <unk>\n",
            "2021-07-27 04:43:05 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 16008 types\n",
            "2021-07-27 04:43:06 | INFO | fairseq_cli.preprocess | [ja] dev.sub.ja: 1166 sents, 32484 tokens, 0.00924% replaced by <unk>\n",
            "2021-07-27 04:43:06 | INFO | fairseq_cli.preprocess | [en] Dictionary: 16008 types\n",
            "2021-07-27 04:44:42 | INFO | fairseq_cli.preprocess | [en] train.sub.7.en: 440288 sents, 20858449 tokens, 0.0% replaced by <unk>\n",
            "2021-07-27 04:44:42 | INFO | fairseq_cli.preprocess | [en] Dictionary: 16008 types\n",
            "2021-07-27 04:44:43 | INFO | fairseq_cli.preprocess | [en] dev.sub.en: 1166 sents, 34466 tokens, 0.0% replaced by <unk>\n",
            "2021-07-27 04:44:43 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data95.7\n",
            "2021-07-27 04:44:44 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data95.8', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='ja', srcdict='ch10/data95.1/dict.ja.txt', target_lang='en', task='translation', tensorboard_logdir=None, testpref=None, tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='train.sub.8', user_dir=None, validpref='dev.sub', workers=16)\n",
            "2021-07-27 04:44:44 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 16008 types\n",
            "2021-07-27 04:46:11 | INFO | fairseq_cli.preprocess | [ja] train.sub.8.ja: 440288 sents, 15799081 tokens, 0.0% replaced by <unk>\n",
            "2021-07-27 04:46:11 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 16008 types\n",
            "2021-07-27 04:46:11 | INFO | fairseq_cli.preprocess | [ja] dev.sub.ja: 1166 sents, 32484 tokens, 0.00924% replaced by <unk>\n",
            "2021-07-27 04:46:11 | INFO | fairseq_cli.preprocess | [en] Dictionary: 16008 types\n",
            "2021-07-27 04:47:47 | INFO | fairseq_cli.preprocess | [en] train.sub.8.en: 440288 sents, 20857203 tokens, 0.0% replaced by <unk>\n",
            "2021-07-27 04:47:48 | INFO | fairseq_cli.preprocess | [en] Dictionary: 16008 types\n",
            "2021-07-27 04:47:48 | INFO | fairseq_cli.preprocess | [en] dev.sub.en: 1166 sents, 34466 tokens, 0.0% replaced by <unk>\n",
            "2021-07-27 04:47:48 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data95.8\n",
            "2021-07-27 04:47:50 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data95.9', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='ja', srcdict='ch10/data95.1/dict.ja.txt', target_lang='en', task='translation', tensorboard_logdir=None, testpref=None, tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='train.sub.9', user_dir=None, validpref='dev.sub', workers=16)\n",
            "2021-07-27 04:47:50 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 16008 types\n",
            "2021-07-27 04:49:15 | INFO | fairseq_cli.preprocess | [ja] train.sub.9.ja: 440288 sents, 15799358 tokens, 0.0% replaced by <unk>\n",
            "2021-07-27 04:49:15 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 16008 types\n",
            "2021-07-27 04:49:16 | INFO | fairseq_cli.preprocess | [ja] dev.sub.ja: 1166 sents, 32484 tokens, 0.00924% replaced by <unk>\n",
            "2021-07-27 04:49:16 | INFO | fairseq_cli.preprocess | [en] Dictionary: 16008 types\n",
            "2021-07-27 04:50:50 | INFO | fairseq_cli.preprocess | [en] train.sub.9.en: 440288 sents, 20859318 tokens, 0.0% replaced by <unk>\n",
            "2021-07-27 04:50:50 | INFO | fairseq_cli.preprocess | [en] Dictionary: 16008 types\n",
            "2021-07-27 04:50:51 | INFO | fairseq_cli.preprocess | [en] dev.sub.en: 1166 sents, 34466 tokens, 0.0% replaced by <unk>\n",
            "2021-07-27 04:50:51 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data95.9\n",
            "2021-07-27 04:50:52 | INFO | fairseq_cli.preprocess | Namespace(align_suffix=None, alignfile=None, all_gather_list_size=16384, bf16=False, bpe=None, checkpoint_shard_count=1, checkpoint_suffix='', cpu=False, criterion='cross_entropy', dataset_impl='mmap', destdir='data95.10', empty_cache_freq=0, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, joined_dictionary=True, log_format=None, log_interval=100, lr_scheduler='fixed', memory_efficient_bf16=False, memory_efficient_fp16=False, min_loss_scale=0.0001, model_parallel_size=1, no_progress_bar=False, nwordssrc=-1, nwordstgt=-1, only_source=False, optimizer=None, padding_factor=8, profile=False, quantization_config_path=None, scoring='bleu', seed=1, source_lang='ja', srcdict='ch10/data95.1/dict.ja.txt', target_lang='en', task='translation', tensorboard_logdir=None, testpref=None, tgtdict=None, threshold_loss_scale=None, thresholdsrc=0, thresholdtgt=0, tokenizer=None, tpu=False, trainpref='train.sub.10', user_dir=None, validpref='dev.sub', workers=16)\n",
            "2021-07-27 04:50:52 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 16008 types\n",
            "2021-07-27 04:52:17 | INFO | fairseq_cli.preprocess | [ja] train.sub.10.ja: 440288 sents, 15800127 tokens, 0.0% replaced by <unk>\n",
            "2021-07-27 04:52:17 | INFO | fairseq_cli.preprocess | [ja] Dictionary: 16008 types\n",
            "2021-07-27 04:52:18 | INFO | fairseq_cli.preprocess | [ja] dev.sub.ja: 1166 sents, 32484 tokens, 0.00924% replaced by <unk>\n",
            "2021-07-27 04:52:18 | INFO | fairseq_cli.preprocess | [en] Dictionary: 16008 types\n",
            "2021-07-27 04:53:52 | INFO | fairseq_cli.preprocess | [en] train.sub.10.en: 440288 sents, 20858112 tokens, 0.0% replaced by <unk>\n",
            "2021-07-27 04:53:52 | INFO | fairseq_cli.preprocess | [en] Dictionary: 16008 types\n",
            "2021-07-27 04:53:53 | INFO | fairseq_cli.preprocess | [en] dev.sub.en: 1166 sents, 34466 tokens, 0.0% replaced by <unk>\n",
            "2021-07-27 04:53:53 | INFO | fairseq_cli.preprocess | Wrote preprocessed data to data95.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OErKJvIzHxxO",
        "outputId": "36a937b9-734e-4e93-e3d5-650d5378c013"
      },
      "source": [
        "!fairseq-train\\\n",
        "  data95.1:data95.2:data95.3:data95.4:data95.5:data95.6:data95.7:data95.8:data95.9:data95.10\\\n",
        "  --fp16 \\\n",
        "  --save-dir save95 \\\n",
        "  --max-epoch 10 \\\n",
        "  --arch transformer \\\n",
        "  --encoder-normalize-before --decoder-normalize-before \\\n",
        "  --share-decoder-input-output-embed \\\n",
        "  --lr 0.001 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 \\\n",
        "  --update-freq 2 \\\n",
        "  --weight-decay 0.0001 \\\n",
        "  --dropout 0.2 --attention-dropout 0.1 --activation-dropout 0.1 \\\n",
        "  --optimizer adam --adam-betas '(0.9, 0.999)' \\\n",
        "  --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
        "  --max-tokens 4096 > 95.log"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 002: 100% 2921/2922 [13:30<00:00,  3.64it/s, loss=5.771, nll_loss=4.46, ppl=22.01, wps=25194.6, ups=3.56, wpb=7080.3, bsz=142.4, num_updates=5800, lr=0.000830455, gnorm=0.416, loss_scale=16, train_wall=28, wall=0]\n",
            "epoch 002 | valid on 'valid' subset:   0% 0/16 [00:00<?, ?it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:   6% 1/16 [00:00<00:01,  7.66it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  25% 4/16 [00:00<00:01,  9.60it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  44% 7/16 [00:00<00:00, 11.74it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  62% 10/16 [00:00<00:00, 13.83it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset:  81% 13/16 [00:00<00:00, 15.52it/s]\u001b[A\n",
            "epoch 002 | valid on 'valid' subset: 100% 16/16 [00:00<00:00, 17.47it/s]\u001b[A\n",
            "epoch 003:  61% 1784/2926 [08:18<05:02,  3.78it/s, loss=5.399, nll_loss=4.04, ppl=16.45, wps=25200, ups=3.54, wpb=7122.3, bsz=156.2, num_updates=7600, lr=0.000725476, gnorm=0.387, loss_scale=16, train_wall=28, wall=0]"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpCzkC0jIYc_"
      },
      "source": [
        "%%bash\n",
        "for N in {1..10}; do\n",
        "  fairseq-interactive data95.1 \\\n",
        "    --path save95/checkpoint10.pt\n",
        "    --buffer-size 128 \\\n",
        "    --batch-size 64 \\\n",
        "    --beam $N \\\n",
        "    --lenpen 0.6 \\\n",
        "    < dev.sub.ja | grep '^H' | cut -f3 > 95.${N}.out\n",
        "done"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_zW-yM9JOuh"
      },
      "source": [
        "def sp_decode(src, dst):\n",
        "  with open(src) as s, open(dst,'w') as d:\n",
        "    for x in s:\n",
        "      x = x.strip().split()\n",
        "      x = ' '.join(x).replace('_', ' ')\n",
        "      print(x, file=d) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDr5okCuJgKr"
      },
      "source": [
        "for i in range(1, 11):\n",
        "  src = '95.{}.out'.format(i)\n",
        "  dst = '95.{}.decoded'.format(i)\n",
        "  sp_decode(src, dst)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj_OLNUbJ6r_"
      },
      "source": [
        "%%bash\n",
        "for N in {1..10}; do\n",
        "  fairseq-score --sys 95.$N.out --ref test.tokenized.en > 95.$N.score\n",
        "done"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4XRZdJ6KzgF"
      },
      "source": [
        "xs = range(1, 11)\n",
        "ys = [read_score(f'95.{x}.score') for x in xs]\n",
        "plt.plot(xs, ys)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nawTlmY0K57C"
      },
      "source": [
        "## 96. 学習過程の可視化"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mscm60ggLEe4"
      },
      "source": [
        "!pip install tensorflow tensorboardX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNJjGA_M79HT"
      },
      "source": [
        "!fairseq-train for91\\\n",
        "  --fp16 \\\n",
        "  --tensorboard-logdir log96\\\n",
        "  --save-dir save96 \\\n",
        "  --max-epoch 3 \\\n",
        "  --arch transformer \\\n",
        "  --encoder-normalize-before --decoder-normalize-before \\\n",
        "  --share-decoder-input-output-embed \\\n",
        "  --lr 0.001 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 \\\n",
        "  --update-freq 2 \\\n",
        "  --weight-decay 0.0001 \\\n",
        "  --dropout 0.2 --attention-dropout 0.1 --activation-dropout 0.1 \\\n",
        "  --optimizer adam --adam-betas '(0.9, 0.999)' \\\n",
        "  --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
        "  --max-tokens 4096 > 96.log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsOiVfzOLaT5"
      },
      "source": [
        "## 97. ハイパー・パラメータの調整"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jM7lbrVsLdIm"
      },
      "source": [
        "!fairseq-train\\\n",
        "  data95.1:data95.2:data95.3:data95.4:data95.5:data95.6:data95.7:data95.8:data95.9:data95.10\\\n",
        "  --fp16 \\\n",
        "  --save-dir save97_1 \\\n",
        "  --max-epoch 10 \\\n",
        "  --arch transformer \\\n",
        "  --encoder-normalize-before --decoder-normalize-before \\\n",
        "  --share-decoder-input-output-embed \\\n",
        "  --lr 0.001 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 \\\n",
        "  --update-freq 2 \\\n",
        "  --weight-decay 0.0001 \\\n",
        "  --dropout 0.2 --attention-dropout 0.1 --activation-dropout 0.1 \\\n",
        "  --optimizer adam --adam-betas '(0.9, 0.999)' \\\n",
        "  --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
        "  --max-tokens 4096 > 97_1.log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zehItwTrRKWu"
      },
      "source": [
        "!fairseq-train\\\n",
        "  data95.1:data95.2:data95.3:data95.4:data95.5:data95.6:data95.7:data95.8:data95.9:data95.10\\\n",
        "  --fp16 \\\n",
        "  --save-dir save97_2 \\\n",
        "  --max-epoch 10 \\\n",
        "  --arch transformer \\\n",
        "  --encoder-normalize-before --decoder-normalize-before \\\n",
        "  --share-decoder-input-output-embed \\\n",
        "  --lr 0.005 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 \\\n",
        "  --update-freq 2 \\\n",
        "  --weight-decay 0.0001 \\\n",
        "  --dropout 0.2 --attention-dropout 0.1 --activation-dropout 0.1 \\\n",
        "  --optimizer adam --adam-betas '(0.9, 0.999)' \\\n",
        "  --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
        "  --max-tokens 4096 > 97_2.log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVhWlobyRgQY"
      },
      "source": [
        "!fairseq-train\\\n",
        "  data95.1:data95.2:data95.3:data95.4:data95.5:data95.6:data95.7:data95.8:data95.9:data95.10\\\n",
        "  --fp16 \\\n",
        "  --save-dir save97_3 \\\n",
        "  --max-epoch 10 \\\n",
        "  --arch transformer \\\n",
        "  --encoder-normalize-before --decoder-normalize-before \\\n",
        "  --share-decoder-input-output-embed \\\n",
        "  --lr 0.01 --lr-scheduler inverse_sqrt --warmup-updates 4000 --warmup-init-lr 1e-07 \\\n",
        "  --update-freq 2 \\\n",
        "  --weight-decay 0.0001 \\\n",
        "  --dropout 0.2 --attention-dropout 0.1 --activation-dropout 0.1 \\\n",
        "  --optimizer adam --adam-betas '(0.9, 0.999)' \\\n",
        "  --criterion label_smoothed_cross_entropy --label-smoothing 0.1 \\\n",
        "  --max-tokens 4096 > 97_3.log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytPhAxtrRxhv"
      },
      "source": [
        "%%bash\n",
        "fairseq-interactive data95.1 \\\n",
        "    --path save97_1/checkpoint10.pt\n",
        "    --buffer-size 128 \\\n",
        "    --batch-size 64 \\\n",
        "    --beam 4 \\\n",
        "    --lenpen 0.6 \\\n",
        "    < dev.sub.ja | grep '^H' | cut -f3 > 97_1.${N}.out\n",
        "done"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mWB7JXISIYD"
      },
      "source": [
        "sp_decode('97_1.out', '97_1.decoded')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEvg9nAOR_Ey"
      },
      "source": [
        "%%bash\n",
        "fairseq-interactive data95.1 \\\n",
        "    --path save97_2/checkpoint10.pt\n",
        "    --buffer-size 128 \\\n",
        "    --batch-size 64 \\\n",
        "    --beam 4 \\\n",
        "    --lenpen 0.6 \\\n",
        "    < dev.sub.ja | grep '^H' | cut -f3 > 97_2.${N}.out\n",
        "done"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScTtXKHISIvs"
      },
      "source": [
        "sp_decode('97_2.out', '97_2.decoded')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUF6-w2hR_or"
      },
      "source": [
        "%%bash\n",
        "fairseq-interactive data95.1 \\\n",
        "    --path save97_3/checkpoint10.pt\n",
        "    --buffer-size 128 \\\n",
        "    --batch-size 64 \\\n",
        "    --beam 4 \\\n",
        "    --lenpen 0.6 \\\n",
        "    < dev.sub.ja | grep '^H' | cut -f3 > 97_3.${N}.out\n",
        "done"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_JI8lJSSJXG"
      },
      "source": [
        "sp_decode('97_3.out', '97_3.decoded')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoGVNwTXSqms"
      },
      "source": [
        "!fairseq-score --sys 97_1.out --ref test.tokenized.en\n",
        "!fairseq-score --sys 97_2.out --ref test.tokenized.en\n",
        "!fairseq-score --sys 97_3.out --ref test.tokenized.en"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4RI-9zCXlsT"
      },
      "source": [
        "## 98. ドメイン適応"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBCRtAkCXoeC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}